{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:19.723562Z",
     "iopub.status.busy": "2023-10-22T21:13:19.722996Z",
     "iopub.status.idle": "2023-10-22T21:13:20.041398Z",
     "shell.execute_reply": "2023-10-22T21:13:20.039790Z",
     "shell.execute_reply.started": "2023-10-22T21:13:19.723318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-summary/news_summary_more.csv\n",
      "/kaggle/input/news-summary/news_summary.csv\n",
      "/kaggle/input/word2vec-for-text-summarization/__results__.html\n",
      "/kaggle/input/word2vec-for-text-summarization/__notebook__.ipynb\n",
      "/kaggle/input/word2vec-for-text-summarization/__output__.json\n",
      "/kaggle/input/word2vec-for-text-summarization/w2v_text_summ_200d_09162019\n",
      "/kaggle/input/word2vec-for-text-summarization/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:22.862611Z",
     "iopub.status.busy": "2023-10-22T21:13:22.862017Z",
     "iopub.status.idle": "2023-10-22T21:13:24.277747Z",
     "shell.execute_reply": "2023-10-22T21:13:24.276672Z",
     "shell.execute_reply.started": "2023-10-22T21:13:22.862540Z"
    }
   },
   "outputs": [],
   "source": [
    "summary = pd.read_csv('/kaggle/input/news-summary/news_summary.csv', encoding='iso-8859-1')\n",
    "raw = pd.read_csv('/kaggle/input/news-summary/news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:30.307965Z",
     "iopub.status.busy": "2023-10-22T21:13:30.307599Z",
     "iopub.status.idle": "2023-10-22T21:13:30.383394Z",
     "shell.execute_reply": "2023-10-22T21:13:30.382442Z",
     "shell.execute_reply.started": "2023-10-22T21:13:30.307911Z"
    }
   },
   "outputs": [],
   "source": [
    "pre1 =  raw.iloc[:,0:2].copy()\n",
    "# pre1['head + text'] = pre1['headlines'].str.cat(pre1['text'], sep =\" \") \n",
    "\n",
    "pre2 = summary.iloc[:,0:6].copy()\n",
    "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:32.585288Z",
     "iopub.status.busy": "2023-10-22T21:13:32.584928Z",
     "iopub.status.idle": "2023-10-22T21:13:32.639798Z",
     "shell.execute_reply": "2023-10-22T21:13:32.638485Z",
     "shell.execute_reply.started": "2023-10-22T21:13:32.585234Z"
    }
   },
   "outputs": [],
   "source": [
    "pre = pd.DataFrame()\n",
    "pre['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
    "pre['summary'] = pd.concat([pre1['headlines'],pre2['headlines']],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:35.011724Z",
     "iopub.status.busy": "2023-10-22T21:13:35.011339Z",
     "iopub.status.idle": "2023-10-22T21:13:35.033771Z",
     "shell.execute_reply": "2023-10-22T21:13:35.032879Z",
     "shell.execute_reply.started": "2023-10-22T21:13:35.011668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "\n",
       "                                             summary  \n",
       "0  upGrad learner switches to career in ML & Al w...  \n",
       "1  Delhi techie wins free food from Swiggy for on...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:41.278109Z",
     "iopub.status.busy": "2023-10-22T21:13:41.277728Z",
     "iopub.status.idle": "2023-10-22T21:13:41.286700Z",
     "shell.execute_reply": "2023-10-22T21:13:41.285551Z",
     "shell.execute_reply.started": "2023-10-22T21:13:41.278057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
       "1    Kunal Shah's credit card bill payment platform...\n",
       "2    New Zealand defeated India by 8 wickets in the...\n",
       "3    With Aegon Life iTerm Insurance plan, customer...\n",
       "4    Speaking about the sexual harassment allegatio...\n",
       "5    Pakistani singer Rahat Fateh Ali Khan has deni...\n",
       "6    India recorded their lowest ODI total in New Z...\n",
       "7    Weeks after ex-CBI Director Alok Verma told th...\n",
       "8    Andhra Pradesh CM N Chandrababu Naidu has said...\n",
       "9    Congress candidate Shafia Zubair won the Ramga...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM with Attention\n",
    "#pip install keras-self-attention\n",
    "\n",
    "pre['text'][:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Perform Data Cleansing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:44.401862Z",
     "iopub.status.busy": "2023-10-22T21:13:44.401504Z",
     "iopub.status.idle": "2023-10-22T21:13:44.426694Z",
     "shell.execute_reply": "2023-10-22T21:13:44.425445Z",
     "shell.execute_reply.started": "2023-10-22T21:13:44.401810Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Removes non-alphabetic characters:\n",
    "def text_strip(column):\n",
    "    for row in column:\n",
    "        \n",
    "        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
    "        \n",
    "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
    "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
    "        \n",
    "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
    "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
    "        \n",
    "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
    "        \n",
    "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
    "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
    "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
    "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
    "        \n",
    "        \n",
    "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
    "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
    "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
    "        \n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "        \n",
    "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
    "        try:\n",
    "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
    "        except:\n",
    "            pass #there might be emails with no url in them\n",
    "        \n",
    "\n",
    "        \n",
    "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
    "        \n",
    "        #Should always be last\n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "\n",
    "        \n",
    "        \n",
    "        yield row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:47.896082Z",
     "iopub.status.busy": "2023-10-22T21:13:47.895720Z",
     "iopub.status.idle": "2023-10-22T21:13:47.901248Z",
     "shell.execute_reply": "2023-10-22T21:13:47.900229Z",
     "shell.execute_reply.started": "2023-10-22T21:13:47.896029Z"
    }
   },
   "outputs": [],
   "source": [
    "brief_cleaning1 = text_strip(pre['text'])\n",
    "brief_cleaning2 = text_strip(pre['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-22T21:13:49.607526Z",
     "iopub.status.busy": "2023-10-22T21:13:49.607135Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process:\n",
    "#If data loss seems to be happening(i.e len(text) = 50 instead of 75 etc etc) in this cell , decrease the batch_size parametre \n",
    "\n",
    "t = time()\n",
    "\n",
    "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
    "text = [str(doc) for doc in nlp.pipe(brief_cleaning1, batch_size=5000, n_threads=-1)]\n",
    "\n",
    "#Takes 7-8 mins\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process:\n",
    "\n",
    "\n",
    "t = time()\n",
    "\n",
    "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
    "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(brief_cleaning2, batch_size=5000, n_threads=-1)]\n",
    "\n",
    "#Takes 7-8 mins\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:33.902278Z",
     "iopub.status.busy": "2023-02-05T14:31:33.901733Z",
     "iopub.status.idle": "2023-02-05T14:31:33.907995Z",
     "shell.execute_reply": "2023-02-05T14:31:33.907254Z",
     "shell.execute_reply.started": "2023-02-05T14:31:33.902224Z"
    }
   },
   "outputs": [],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:33.909708Z",
     "iopub.status.busy": "2023-02-05T14:31:33.909278Z",
     "iopub.status.idle": "2023-02-05T14:31:33.919063Z",
     "shell.execute_reply": "2023-02-05T14:31:33.918443Z",
     "shell.execute_reply.started": "2023-02-05T14:31:33.909661Z"
    }
   },
   "outputs": [],
   "source": [
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:33.921279Z",
     "iopub.status.busy": "2023-02-05T14:31:33.92068Z",
     "iopub.status.idle": "2023-02-05T14:31:33.962339Z",
     "shell.execute_reply": "2023-02-05T14:31:33.961711Z",
     "shell.execute_reply.started": "2023-02-05T14:31:33.921055Z"
    }
   },
   "outputs": [],
   "source": [
    "pre['cleaned_text'] = pd.Series(text)\n",
    "pre['cleaned_summary'] = pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:33.963876Z",
     "iopub.status.busy": "2023-02-05T14:31:33.963594Z",
     "iopub.status.idle": "2023-02-05T14:31:33.969849Z",
     "shell.execute_reply": "2023-02-05T14:31:33.967602Z",
     "shell.execute_reply.started": "2023-02-05T14:31:33.96383Z"
    }
   },
   "outputs": [],
   "source": [
    "text_count = []\n",
    "summary_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:33.971613Z",
     "iopub.status.busy": "2023-02-05T14:31:33.97115Z",
     "iopub.status.idle": "2023-02-05T14:31:34.530466Z",
     "shell.execute_reply": "2023-02-05T14:31:34.529429Z",
     "shell.execute_reply.started": "2023-02-05T14:31:33.97154Z"
    }
   },
   "outputs": [],
   "source": [
    "for sent in pre['cleaned_text']:\n",
    "    text_count.append(len(sent.split()))\n",
    "for sent in pre['cleaned_summary']:\n",
    "    summary_count.append(len(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:34.535008Z",
     "iopub.status.busy": "2023-02-05T14:31:34.534702Z",
     "iopub.status.idle": "2023-02-05T14:31:34.608521Z",
     "shell.execute_reply": "2023-02-05T14:31:34.607875Z",
     "shell.execute_reply.started": "2023-02-05T14:31:34.534959Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_df= pd.DataFrame()\n",
    "graph_df['text']=text_count\n",
    "graph_df['summary']=summary_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:34.610744Z",
     "iopub.status.busy": "2023-02-05T14:31:34.6102Z",
     "iopub.status.idle": "2023-02-05T14:31:34.870595Z",
     "shell.execute_reply": "2023-02-05T14:31:34.86945Z",
     "shell.execute_reply.started": "2023-02-05T14:31:34.610538Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph_df.hist(bins = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:34.872725Z",
     "iopub.status.busy": "2023-02-05T14:31:34.872208Z",
     "iopub.status.idle": "2023-02-05T14:31:34.974876Z",
     "shell.execute_reply": "2023-02-05T14:31:34.973844Z",
     "shell.execute_reply.started": "2023-02-05T14:31:34.872516Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check how much % of summary have 0-15 words\n",
    "cnt=0\n",
    "for i in pre['cleaned_summary']:\n",
    "    if(len(i.split())<=15):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(pre['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:34.976783Z",
     "iopub.status.busy": "2023-02-05T14:31:34.976341Z",
     "iopub.status.idle": "2023-02-05T14:31:35.382948Z",
     "shell.execute_reply": "2023-02-05T14:31:35.382127Z",
     "shell.execute_reply.started": "2023-02-05T14:31:34.976588Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check how much % of text have 0-70 words\n",
    "cnt=0\n",
    "for i in pre['cleaned_text']:\n",
    "    if(len(i.split())<=100):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(pre['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:35.384732Z",
     "iopub.status.busy": "2023-02-05T14:31:35.384278Z",
     "iopub.status.idle": "2023-02-05T14:31:35.389001Z",
     "shell.execute_reply": "2023-02-05T14:31:35.388054Z",
     "shell.execute_reply.started": "2023-02-05T14:31:35.384681Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
    "max_text_len=100\n",
    "max_summary_len=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:35.390923Z",
     "iopub.status.busy": "2023-02-05T14:31:35.390461Z",
     "iopub.status.idle": "2023-02-05T14:31:36.19767Z",
     "shell.execute_reply": "2023-02-05T14:31:36.196947Z",
     "shell.execute_reply.started": "2023-02-05T14:31:35.390874Z"
    }
   },
   "outputs": [],
   "source": [
    "#Select the Summaries and Text between max len defined above\n",
    "\n",
    "cleaned_text =np.array(pre['cleaned_text'])\n",
    "cleaned_summary=np.array(pre['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "post_pre=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:36.199386Z",
     "iopub.status.busy": "2023-02-05T14:31:36.199092Z",
     "iopub.status.idle": "2023-02-05T14:31:36.215526Z",
     "shell.execute_reply": "2023-02-05T14:31:36.214643Z",
     "shell.execute_reply.started": "2023-02-05T14:31:36.19934Z"
    }
   },
   "outputs": [],
   "source": [
    "post_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:36.217674Z",
     "iopub.status.busy": "2023-02-05T14:31:36.217141Z",
     "iopub.status.idle": "2023-02-05T14:31:36.257494Z",
     "shell.execute_reply": "2023-02-05T14:31:36.25687Z",
     "shell.execute_reply.started": "2023-02-05T14:31:36.217624Z"
    }
   },
   "outputs": [],
   "source": [
    "#Add sostok and eostok at \n",
    "post_pre['summary'] = post_pre['summary'].apply(lambda x : 'sostok '+ x + ' eostok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:36.259429Z",
     "iopub.status.busy": "2023-02-05T14:31:36.259014Z",
     "iopub.status.idle": "2023-02-05T14:31:36.269374Z",
     "shell.execute_reply": "2023-02-05T14:31:36.268248Z",
     "shell.execute_reply.started": "2023-02-05T14:31:36.259269Z"
    }
   },
   "outputs": [],
   "source": [
    "post_pre.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SEQ2SEQ MODEL BUILDING **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data to TRAIN and VALIDATION sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:36.271427Z",
     "iopub.status.busy": "2023-02-05T14:31:36.270906Z",
     "iopub.status.idle": "2023-02-05T14:31:36.856777Z",
     "shell.execute_reply": "2023-02-05T14:31:36.855828Z",
     "shell.execute_reply.started": "2023-02-05T14:31:36.271164Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:36.858674Z",
     "iopub.status.busy": "2023-02-05T14:31:36.858388Z",
     "iopub.status.idle": "2023-02-05T14:31:43.20518Z",
     "shell.execute_reply": "2023-02-05T14:31:43.204201Z",
     "shell.execute_reply.started": "2023-02-05T14:31:36.858627Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lets tokenize the text to get the vocab count , you can use Spacy here also\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RARE WORD ANALYSIS FOR X i.e 'text'**\n",
    "* tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
    "\n",
    "* cnt gives me the no. of rare words whose count falls below threshold\n",
    "\n",
    "* tot_cnt - cnt gives me the top most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:43.207004Z",
     "iopub.status.busy": "2023-02-05T14:31:43.206664Z",
     "iopub.status.idle": "2023-02-05T14:31:43.265084Z",
     "shell.execute_reply": "2023-02-05T14:31:43.26443Z",
     "shell.execute_reply.started": "2023-02-05T14:31:43.206953Z"
    }
   },
   "outputs": [],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:43.268398Z",
     "iopub.status.busy": "2023-02-05T14:31:43.268163Z",
     "iopub.status.idle": "2023-02-05T14:31:54.419494Z",
     "shell.execute_reply": "2023-02-05T14:31:54.418673Z",
     "shell.execute_reply.started": "2023-02-05T14:31:43.268353Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RARE WORD ANALYSIS FOR Y i.e 'summary'**\n",
    "* tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
    "\n",
    "* cnt gives me the no. of rare words whose count falls below threshold\n",
    "\n",
    "* tot_cnt - cnt gives me the top most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:54.42134Z",
     "iopub.status.busy": "2023-02-05T14:31:54.420851Z",
     "iopub.status.idle": "2023-02-05T14:31:56.562901Z",
     "shell.execute_reply": "2023-02-05T14:31:56.56216Z",
     "shell.execute_reply.started": "2023-02-05T14:31:54.421277Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:56.564726Z",
     "iopub.status.busy": "2023-02-05T14:31:56.564432Z",
     "iopub.status.idle": "2023-02-05T14:31:56.589888Z",
     "shell.execute_reply": "2023-02-05T14:31:56.588899Z",
     "shell.execute_reply.started": "2023-02-05T14:31:56.564676Z"
    }
   },
   "outputs": [],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:31:56.591843Z",
     "iopub.status.busy": "2023-02-05T14:31:56.591242Z",
     "iopub.status.idle": "2023-02-05T14:32:00.974941Z",
     "shell.execute_reply": "2023-02-05T14:32:00.974082Z",
     "shell.execute_reply.started": "2023-02-05T14:31:56.59161Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove \"Summary\" i.e Y (both train and val) which has only _START_ and _END_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:32:00.97993Z",
     "iopub.status.busy": "2023-02-05T14:32:00.979536Z",
     "iopub.status.idle": "2023-02-05T14:32:03.473452Z",
     "shell.execute_reply": "2023-02-05T14:32:03.472726Z",
     "shell.execute_reply.started": "2023-02-05T14:32:00.979738Z"
    }
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:32:03.476427Z",
     "iopub.status.busy": "2023-02-05T14:32:03.475939Z",
     "iopub.status.idle": "2023-02-05T14:32:03.764339Z",
     "shell.execute_reply": "2023-02-05T14:32:03.763367Z",
     "shell.execute_reply.started": "2023-02-05T14:32:03.476375Z"
    }
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:32:03.766237Z",
     "iopub.status.busy": "2023-02-05T14:32:03.765914Z",
     "iopub.status.idle": "2023-02-05T14:32:06.343603Z",
     "shell.execute_reply": "2023-02-05T14:32:06.342861Z",
     "shell.execute_reply.started": "2023-02-05T14:32:03.766184Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "import gensim\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:32:06.345173Z",
     "iopub.status.busy": "2023-02-05T14:32:06.344891Z",
     "iopub.status.idle": "2023-02-05T14:32:06.394644Z",
     "shell.execute_reply": "2023-02-05T14:32:06.394044Z",
     "shell.execute_reply.started": "2023-02-05T14:32:06.345128Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:32:06.39619Z",
     "iopub.status.busy": "2023-02-05T14:32:06.395909Z",
     "iopub.status.idle": "2023-02-05T14:32:06.401441Z",
     "shell.execute_reply": "2023-02-05T14:32:06.400485Z",
     "shell.execute_reply.started": "2023-02-05T14:32:06.39614Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start fitting the model with the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T14:32:06.403922Z",
     "iopub.status.busy": "2023-02-05T14:32:06.403145Z"
    }
   },
   "outputs": [],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the model learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, let’s build the dictionary to convert the index to word for target and source vocabulary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are defining a function below which is the implementation of the inference process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the model over the data to see the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
